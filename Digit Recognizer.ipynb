{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n***MNIST (\"Modified National Institute of Standards and Technology\")*** Handwritten Digit dataset is the de facto “hello world” dataset of computer vision.  \n  \nSince its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. A new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike. In this competition, the goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We will be experimenting with different algorithms to learn first-hand what works well and how techniques compare.","metadata":{"id":"J9TUK5utCQsz"}},{"cell_type":"markdown","source":"---\n# 1) ***Initialization and preparation***\n---\n## 1.1 Import necessary modules","metadata":{"id":"UlGPQqDyF9Ff"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nfrom keras.utils.vis_utils import plot_model\nfrom catboost import CatBoostClassifier\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)","metadata":{"id":"adf1a8e7","execution":{"iopub.status.busy":"2022-03-21T08:15:10.582565Z","iopub.execute_input":"2022-03-21T08:15:10.583455Z","iopub.status.idle":"2022-03-21T08:15:17.861601Z","shell.execute_reply.started":"2022-03-21T08:15:10.583300Z","shell.execute_reply":"2022-03-21T08:15:17.860739Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Read MNIST data set","metadata":{"id":"OLQ57e4aFrj-"}},{"cell_type":"code","source":"df = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')","metadata":{"id":"c1e11a97","execution":{"iopub.status.busy":"2022-03-21T08:15:31.305108Z","iopub.execute_input":"2022-03-21T08:15:31.306214Z","iopub.status.idle":"2022-03-21T08:15:37.605496Z","shell.execute_reply.started":"2022-03-21T08:15:31.306169Z","shell.execute_reply":"2022-03-21T08:15:37.604493Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Check for digits with missing labels","metadata":{"id":"oOvDc4YrHXXI"}},{"cell_type":"code","source":"print(\"Missing values in train dataset: {}\".format(df.isnull().sum().sum()))\nprint(\"Missing values in test dataset: {}\".format(test.isnull().sum().sum()))","metadata":{"id":"I-aMe9XIH2GG","execution":{"iopub.status.busy":"2022-03-21T08:15:37.607753Z","iopub.execute_input":"2022-03-21T08:15:37.608202Z","iopub.status.idle":"2022-03-21T08:15:37.695503Z","shell.execute_reply.started":"2022-03-21T08:15:37.608156Z","shell.execute_reply":"2022-03-21T08:15:37.694536Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"There is no missing values in the train and test dataset.","metadata":{}},{"cell_type":"markdown","source":"---\n# 2) Data visualization\n---\n## 2.1 Target distribution","metadata":{"id":"0Q1wBEJ2FvA-"}},{"cell_type":"code","source":"print(\"\\n\")\nprint(df.label.value_counts())\nprint(\"\\n\")\nsns.countplot(df.label)\nplt.title(\"Distribution of handwritten digits\")\nplt.show()","metadata":{"id":"jGDYtaxVBEhQ","outputId":"0e6dbe22-337f-4d78-bf09-1d32851669db","execution":{"iopub.status.busy":"2022-03-21T08:15:37.697177Z","iopub.execute_input":"2022-03-21T08:15:37.697669Z","iopub.status.idle":"2022-03-21T08:15:37.963282Z","shell.execute_reply.started":"2022-03-21T08:15:37.697626Z","shell.execute_reply":"2022-03-21T08:15:37.962355Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Check out data columns (image pixel size) and labels","metadata":{}},{"cell_type":"code","source":"print(\"Train data set columns: {}\".format(df.columns))\nprint(\"Test data set columns: {}\".format(test.columns))\nprint(\"No of pixels: {}\".format(len(test.columns)))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:15:37.964761Z","iopub.execute_input":"2022-03-21T08:15:37.965574Z","iopub.status.idle":"2022-03-21T08:15:37.974713Z","shell.execute_reply.started":"2022-03-21T08:15:37.965496Z","shell.execute_reply":"2022-03-21T08:15:37.973239Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Visualize pixels as images","metadata":{"id":"Imcj52PoGRWs"}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=4)\nfor i in range(4):\n    ax[i].set_title(\"Number {}\".format(df.loc[i][0]))\n    ax[i].imshow(np.array(df.loc[i][1:]).reshape(28,28),cmap='gray')\n    ax[i].axis('off')\nfig.tight_layout(pad=0.0)\nplt.show()","metadata":{"id":"6dbc9466","outputId":"fc0cc6b4-488a-435d-84c1-e5c81771c549","execution":{"iopub.status.busy":"2022-03-21T08:15:37.977936Z","iopub.execute_input":"2022-03-21T08:15:37.978878Z","iopub.status.idle":"2022-03-21T08:15:38.239429Z","shell.execute_reply.started":"2022-03-21T08:15:37.978836Z","shell.execute_reply":"2022-03-21T08:15:38.238527Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"---\n# 3.0 Modelling\n---","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Train-development split of data\nWe first split the dataset into training and developmental data set with train_test_split.","metadata":{"id":"gHBk8J5aFijU"}},{"cell_type":"code","source":"train, dev = train_test_split(df,test_size = 0.2, random_state = 42)","metadata":{"id":"EDMD-LLoHefD","execution":{"iopub.status.busy":"2022-03-21T08:15:38.242438Z","iopub.execute_input":"2022-03-21T08:15:38.243251Z","iopub.status.idle":"2022-03-21T08:15:38.522565Z","shell.execute_reply.started":"2022-03-21T08:15:38.243196Z","shell.execute_reply":"2022-03-21T08:15:38.521496Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model\nWe incorporate some baseline models which are less complex to see how much we can do in as little time as possible, then optimize from there upwards.  \nWe will be using:\n* Logistic Regression (Multinomial)\n* Cat Gradient Boosting Classifier\n* K Nearest Neighbors\n* Support Vector Classifier","metadata":{"id":"cd67ebfa"}},{"cell_type":"code","source":"logreg = LogisticRegression(multi_class='multinomial')\nlogreg.fit(train.drop('label',axis=1),train.label)\nlogreg_pred = logreg.predict(dev.drop('label',axis=1))\nprint(\"Accuracy : {}\".format(round(accuracy_score(dev.label,logreg_pred),4)))","metadata":{"id":"38bda7be","outputId":"49084054-dafb-4ea7-e80f-0ef7fd3431b2","execution":{"iopub.status.busy":"2022-03-21T08:15:38.524411Z","iopub.execute_input":"2022-03-21T08:15:38.524786Z","iopub.status.idle":"2022-03-21T08:16:06.558937Z","shell.execute_reply.started":"2022-03-21T08:15:38.524731Z","shell.execute_reply":"2022-03-21T08:16:06.555416Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"cat = CatBoostClassifier(loss_function='MultiClass',n_estimators = 100,verbose = 0)\ncat.fit(train.drop('label',axis=1),train.label, eval_set=(dev.drop('label',axis=1), dev.label))\ncat_pred = cat.predict(dev.drop('label',axis=1))\nprint(\"Accuracy : {}\".format(round(accuracy_score(dev.label,cat_pred),4)))","metadata":{"id":"b3499cd3","outputId":"b9eb42d2-e46e-4d2b-c358-fd686e9d3128","execution":{"iopub.status.busy":"2022-03-21T08:16:06.560588Z","iopub.execute_input":"2022-03-21T08:16:06.561011Z","iopub.status.idle":"2022-03-21T08:20:06.289349Z","shell.execute_reply.started":"2022-03-21T08:16:06.560969Z","shell.execute_reply":"2022-03-21T08:20:06.288377Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 1)\nknn.fit(train.drop('label',axis=1),train.label)\nknn_pred = knn.predict(dev.drop('label',axis=1))\nprint(\"Accuracy : {}\".format(round(accuracy_score(dev.label,knn_pred),4)))","metadata":{"id":"c63836b1","outputId":"4725d6e0-7680-437a-8431-374f06bf880d","execution":{"iopub.status.busy":"2022-03-21T08:20:06.290952Z","iopub.execute_input":"2022-03-21T08:20:06.292625Z","iopub.status.idle":"2022-03-21T08:20:24.065217Z","shell.execute_reply.started":"2022-03-21T08:20:06.292568Z","shell.execute_reply":"2022-03-21T08:20:24.064279Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"svc = SVC()\nsvc.fit(train.drop('label',axis=1),train.label)\nsvc_pred = svc.predict(dev.drop('label',axis=1))\nprint(\"Accuracy : {}\".format(round(accuracy_score(dev.label,svc_pred),4)))","metadata":{"id":"7d6be2f7","outputId":"42b9a7da-8822-4d06-ebb1-a14b90c290c1","execution":{"iopub.status.busy":"2022-03-21T08:20:24.066678Z","iopub.execute_input":"2022-03-21T08:20:24.067088Z","iopub.status.idle":"2022-03-21T08:22:45.562216Z","shell.execute_reply.started":"2022-03-21T08:20:24.067044Z","shell.execute_reply":"2022-03-21T08:22:45.561212Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We can see that our baseline models can already do a pretty good work with > 97% accuracy to predict the digits. Can we do better with a more complex model?","metadata":{}},{"cell_type":"markdown","source":"---\n# Convolutional Neural Network\n---\nThis will be our main model used to predict the test data set. The reason why we picked it as our final model is because CNN has had a great reputation with dealing with images especially large images. There are several reasons why and how:  \n  \n* CNN is particularly useful as the ***convolutional layer*** can be used to automatically extract important features from the images and gradually build up to a higher-level more important features as the layers get deeper. We chose to use ***same padding*** to pad around image edges during the convolutional process as the original image size is already small enough (28 x 28 pixels) and we can't afford to lose too many important data.  \n\n* We also add in ***MaxPooling*** into our convolutional neural network (though only 2 times) although it can downsize the image sizes but it does increase training speed while it subsamples the image. At the same time, MaxPooling preserve the most important feature while downsizing and offers a benefit of translation invariance (the network learns to desensitize itself against fixed location so that it doesn't remember where the pixel location starts.)  \n  \n* ***BatchNormalization*** is also introduced within the layers to allow every layer of the network to do learning more independently. It is used to normalize the output of neurons and makes learning faster.  \n\n* For regularization, other than BatchNormaliztion, we also tried out using ***Spatial Dropout***. It performs simillar function as Dropout, however, it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.\n  \n* For the activation layer, we used the famous ***ReLu activation function*** as ReLu is empirically found to work well. Papers have observed that training a deep network with ReLu tended to converge much more quickly and reliably than training a deep network with a normal sigmoid activation. It also introduces non-linearity into the model at the same time.  \n  \n* Finally, we ***flatten*** the image as feature columns and pass it into a neural network with ***two hidden layers*** and one ***output layer with softmax*** to denote the probability distributions for each target.\n\n* Note that we also added two data augmentation layer infront of the model to increase our data sizes. We did ***random rotation*** of image up to 18% and a ***random zoom*** of height or width within 20%.\n\nThe full model plot can be seen below after defining the model.\n\nWhile fitting the model, we include ***early stopping*** to prevent our model from overfitting to the training set due to its complexity.  \nOther than that, we try to squeeze every possible juice using ***Reduce Learning Rate on Plateau*** as models often benefit from reducing the learning rate when learning stagnates.\n\nV2.0: To further compete on the leaderboard, we further optimize the model's ability to generalize by using an ensemble of 5 CNN (though the same layers). We sum up the probability distributions before we perform argmax over the distribution (so it is somewhat similar to voting, but more accurate). Using the same model but different fitting process will often end up with different results, this is due to stochastic nature of random initializing the weights of the neurons.\n\n---\nBut first, we will divide the values of pixels within the train, development and test sets by 255 to normalize the pixels.  \nAfter that we will reshape them so that they can fit into the input layer of the Keras API.","metadata":{"id":"J29T6GU9IE8a"}},{"cell_type":"code","source":"train_X = train.drop('label',axis=1).values\ntrain_X = train_X / 255\ntrain_X = train_X.reshape(-1,28,28,1)\n\ndev_X = dev.drop('label',axis=1).values\ndev_X = dev_X / 255\ndev_X = dev_X.reshape(-1,28,28,1)\n\ntrain_y = train.label.values\ntrain_y = train_y.reshape(-1,1)\n\ndev_y = dev.label.values\ndev_y = dev_y.reshape(-1,1)\n\ntest = test.values / 255\ntest = test.reshape(-1,28,28,1)","metadata":{"id":"992b46d1","execution":{"iopub.status.busy":"2022-03-21T08:22:45.563705Z","iopub.execute_input":"2022-03-21T08:22:45.564687Z","iopub.status.idle":"2022-03-21T08:22:45.904510Z","shell.execute_reply.started":"2022-03-21T08:22:45.564639Z","shell.execute_reply":"2022-03-21T08:22:45.903671Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.RandomRotation(factor=0.05, fill_mode='constant'))  \nmodel.add(layers.RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2), fill_mode='constant'))\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same',strides = 1, input_shape=(28, 28, 1)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(32, (5, 5), activation='relu', padding = 'same',strides = 1))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same',strides = 1))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same',strides = 1))\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(layers.SpatialDropout2D(0.4))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same',strides = 1))\nmodel.add(layers.BatchNormalization())\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same',strides = 1))\nmodel.add(layers.BatchNormalization())\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same',strides = 1))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same',strides = 1))\nmodel.add(layers.BatchNormalization())\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(52, activation='relu'))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Dense(26, activation='relu'))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Dense(10,activation = 'softmax'))","metadata":{"id":"440e5f72","execution":{"iopub.status.busy":"2022-03-21T08:22:45.906413Z","iopub.execute_input":"2022-03-21T08:22:45.906743Z","iopub.status.idle":"2022-03-21T08:22:48.728388Z","shell.execute_reply.started":"2022-03-21T08:22:45.906699Z","shell.execute_reply":"2022-03-21T08:22:48.727475Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"early_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=15,\n    min_delta = 0.0001,\n    restore_best_weights=True,\n)\n\nreduce_lr = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    min_lr=0.00001,\n    factor=0.7,\n    patience=5\n)","metadata":{"id":"54GBCMKbmUOp","execution":{"iopub.status.busy":"2022-03-21T08:22:49.594355Z","iopub.execute_input":"2022-03-21T08:22:49.594657Z","iopub.status.idle":"2022-03-21T08:22:49.600483Z","shell.execute_reply.started":"2022-03-21T08:22:49.594616Z","shell.execute_reply":"2022-03-21T08:22:49.599477Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model_count = 5\nhistory  = [0] * model_count\nresults = [0] * model_count\ndev_results = [0] * model_count\n\n\nfor i in range(model_count):\n  print(\"Model {}\".format(i + 1))\n  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n  history[i] = model.fit(train_X,train_y,\n      validation_data=(dev_X,dev_y),\n      batch_size=64,\n      callbacks=[early_stopping, reduce_lr],\n      epochs=100,\n      verbose=1)\n\n  results[i] = model.predict(test)\n  dev_results[i] = model.predict(dev_X)","metadata":{"id":"5d6407f7","outputId":"2c8551a3-4b94-4b5e-e96d-bcbb7424bdd6","execution":{"iopub.status.busy":"2022-03-21T08:22:49.602357Z","iopub.execute_input":"2022-03-21T08:22:49.603138Z","iopub.status.idle":"2022-03-21T08:36:05.084811Z","shell.execute_reply.started":"2022-03-21T08:22:49.603092Z","shell.execute_reply":"2022-03-21T08:36:05.083774Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plot_model(model, show_shapes=True, show_layer_names=True)","metadata":{"id":"tTM-EyZs665G","outputId":"aec072ea-a01c-48dc-9580-52e99207c9d3","execution":{"iopub.status.busy":"2022-03-21T08:37:01.507030Z","iopub.execute_input":"2022-03-21T08:37:01.507352Z","iopub.status.idle":"2022-03-21T08:37:01.870998Z","shell.execute_reply.started":"2022-03-21T08:37:01.507321Z","shell.execute_reply":"2022-03-21T08:37:01.869417Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"As we mentioned, the final results were taken by using the argmax of the sum of five different probability distributions from five different networks.","metadata":{}},{"cell_type":"code","source":"ensemble_cnn_pred = np.argmax(sum(results),axis = 1)\nensemble_cnn_dev = np.argmax(sum(dev_results),axis = 1)","metadata":{"id":"MEdhOeVncuNa","execution":{"iopub.status.busy":"2022-03-21T08:36:05.086701Z","iopub.execute_input":"2022-03-21T08:36:05.087025Z","iopub.status.idle":"2022-03-21T08:36:05.096331Z","shell.execute_reply.started":"2022-03-21T08:36:05.086980Z","shell.execute_reply":"2022-03-21T08:36:05.095067Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"---\n# 4.0 Results Visualization\n---\nHere, we plot and observe one of the training history among the five networks.  \nWe also plot the confusion matrix of the developmental data to see which are the most frequent incorrect numbers.  \n(We could work on from there by adding more of such data, but due to the nature of the competition, I did not add in more additional data.)","metadata":{}},{"cell_type":"code","source":"# Plot the loss and accuracy curves for one of the networks \nfig, ax = plt.subplots(2,1, figsize=(18, 10))\nax[0].plot(history[0].history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history[0].history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history[0].history['sparse_categorical_accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history[0].history['val_sparse_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"id":"OHHKO1a37ebV","outputId":"6fd51525-f7ee-4e7d-d976-fc4648d97a22","execution":{"iopub.status.busy":"2022-03-21T08:36:05.098511Z","iopub.execute_input":"2022-03-21T08:36:05.098891Z","iopub.status.idle":"2022-03-21T08:36:05.600864Z","shell.execute_reply.started":"2022-03-21T08:36:05.098843Z","shell.execute_reply":"2022-03-21T08:36:05.599868Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"if_cm = confusion_matrix(dev_y, ensemble_cnn_dev)\nsns.heatmap(if_cm, annot=True,annot_kws={\"size\": 16},fmt='g')\nplt.title(\"Ensemble CNN Confusion Matrix\")\nplt.show()","metadata":{"id":"YlSKO38wDbE2","execution":{"iopub.status.busy":"2022-03-21T08:36:05.602565Z","iopub.execute_input":"2022-03-21T08:36:05.603040Z","iopub.status.idle":"2022-03-21T08:36:06.287345Z","shell.execute_reply.started":"2022-03-21T08:36:05.602999Z","shell.execute_reply":"2022-03-21T08:36:06.286357Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=4)\nfor i in range(4):\n    ax[i].set_title(\"Number {}\".format(ensemble_cnn_pred[i]))\n    ax[i].imshow(np.array(test[i][:]).reshape(28,28),cmap='gray')\n    ax[i].axis('off')\nfig.tight_layout(pad=0.0)\nplt.show()","metadata":{"id":"rIKLtj1CaomR","outputId":"2512d139-fbc8-4e8b-8f3f-545735d37ef9","execution":{"iopub.status.busy":"2022-03-21T08:36:06.289275Z","iopub.execute_input":"2022-03-21T08:36:06.289938Z","iopub.status.idle":"2022-03-21T08:36:06.561312Z","shell.execute_reply.started":"2022-03-21T08:36:06.289891Z","shell.execute_reply":"2022-03-21T08:36:06.560342Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"---\n# 5.0 Submission\n---\nThe models achieved a combined accuracy of 99.546% which places me around Top 7 ~ 8 % in the leaderboard as of writing.","metadata":{}},{"cell_type":"code","source":"submission=pd.DataFrame(zip(list(range(1,len(ensemble_cnn_pred)+1)),ensemble_cnn_pred),columns=['ImageId','Label'])\nsubmission.to_csv('submission.csv',index = False)","metadata":{"id":"WPp8Ck7Adu8y","execution":{"iopub.status.busy":"2022-03-21T08:36:06.563150Z","iopub.execute_input":"2022-03-21T08:36:06.563779Z","iopub.status.idle":"2022-03-21T08:36:06.653358Z","shell.execute_reply.started":"2022-03-21T08:36:06.563731Z","shell.execute_reply":"2022-03-21T08:36:06.652427Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Thanks!\nIf you have any questions, comments or suggestions feel free to comment. It would be much appreciated!","metadata":{}}]}